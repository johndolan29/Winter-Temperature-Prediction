{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b2a104",
   "metadata": {},
   "source": [
    "# UK Winter Temperature prediction\n",
    "\n",
    "\n",
    "The aim of this project is to collect open data on climate indices and weather to predict whether the UK will have a colder than average winter this year. This is especially relevant for the winter of 2022/2023 with the war in Ukraine causing massive Gas and Oil problems for the UK and Europe as a whole.\n",
    "\n",
    "So, the question we are asking is: <br /> <br />\n",
    "\n",
    "### Can we use the Climate Indices data from the Autumn months to predict/estimate the mean upcoming winter temperature?\n",
    "<br />\n",
    "\n",
    "Data Sources listed below:\n",
    "\n",
    "\n",
    "AO - https://www.cpc.ncep.noaa.gov/products/precip/CWlink/daily_ao_index/monthly.ao.index.b50.current.ascii <br />\n",
    "The Arctic Oscillation (AO) measures the back-and-forth shifting of atmospheric pressure between the Arctic and the mid-latitudes of the North Pacific and North Atlantic. When the AO is strongly positive, a strong mid-latitude jet stream steers storms northward, reducing cold air outbreaks in the mid-latitudes. When the AO is strongly negative, a weaker, meandering jet dips farther south, allowing Arctic  air to spill into the mid-latitudes. (source: https://www.climate.gov/news-features/understanding-climate/climate-variability-arctic-oscillation) <br /><br />\n",
    "\n",
    "NAO - https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii <br />\n",
    "The NAO (North Atlantic Oscillation) is a weather phenomenon over the North Atlantic Ocean of fluctuations in the difference of atmospheric pressure at sea level (SLP) between the Icelandic Low and the Azores High. (source: https://en.wikipedia.org/wiki/North_Atlantic_oscillation \n",
    "<br /><br />\n",
    "\n",
    "PNA - https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.pna.monthly.b5001.current.ascii <br />\n",
    "The Pacific/North American teleconnection pattern (PNA) is one of the most recognized, influential climate patterns in the Northern Hemisphere mid-latitudes beyond the tropics. It consists of anomalies in the geopotential height fields (typically at 700 or 500mb) observed over the western and eastern United States. It is important to note that the PNA has been found to be strongly influenced by the El Niño-Southern Oscillation (ENSO) phenomenon. The positive phase of the PNA pattern tends to be associated with Pacific warm episodes (El Niño), and the negative phase tends to be associated with Pacific cold episodes (La Niña). (source: https://legacy.climate.ncsu.edu/climate/patterns/pna)\n",
    "<br /><br />\n",
    "\n",
    "nino3.4 - https://origin.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/detrend.nino34.ascii.txt <br />\n",
    "El Niño (La Niña) is a phenomenon in the equatorial Pacific Ocean characterized by a five consecutive 3-month running mean of sea surface temperature (SST) anomalies in the Niño 3.4 region that is above (below) the threshold of +0.5°C (-0.5°C). \n",
    "(source: https://www.ncei.noaa.gov/access/monitoring/enso/sst)\n",
    "<br /><br />\n",
    "\n",
    "PDO - https://www.ncei.noaa.gov/pub/data/cmb/ersst/v5/index/ersst.v5.pdo.dat <br />\n",
    "The Pacific Decadal Oscillation (PDO) is often described as a long-lived El Niño-like pattern of Pacific climate variability (Zhang et al. 1997). As seen with the better-known El Niño/Southern Oscillation (ENSO), extremes in the PDO pattern are marked by widespread variations in the Pacific Basin and the North American climate.(source: https://www.ncei.noaa.gov/access/monitoring/pdo/)\n",
    "<br /><br />\n",
    "\n",
    "SOI - https://crudata.uea.ac.uk/cru/data/soi/soi.dat <br />\n",
    "The Southern Oscillation Index (SOI) is a standardized index based on the observed sea level pressure (SLP) differences between Tahiti and Darwin, Australia. The SOI is one measure of the large-scale fluctuations in air pressure occurring between the western and eastern tropical Pacific (i.e., the state of the Southern Oscillation) during El Niño and La Niña episodes.\n",
    "(source: https://www.ncei.noaa.gov/access/monitoring/enso/soi)\n",
    "<br /><br />\n",
    "\n",
    "QBO - https://www.cpc.ncep.noaa.gov/data/indices/qbo.u50.index <br />\n",
    "The Quasi-Biennial Oscillation is a regular variation of the winds that blow high above the equator. Strong winds in the stratosphere travel in a belt around the planet, and every 14 months or so, these winds completely change direction. \n",
    "(source: https://www.metoffice.gov.uk/weather/learn-about/weather/atmosphere/quasi-biennial-oscillation)\n",
    "<br /><br />\n",
    "\n",
    "Sunspots - https://services.swpc.noaa.gov/json/solar-cycle/observed-solar-cycle-indices.json <br />\n",
    "(source: https://en.wikipedia.org/wiki/Solar_activity_and_climate)\n",
    "<br /><br />\n",
    "\n",
    "AMO - https://psl.noaa.gov/data/correlation/amon.us.data <br />\n",
    "The Atlantic Multi-decadal Oscillation (AMO) has been identified as a coherent mode of natural variability occurring in the North Atlantic Ocean with an estimated period of 60-80 years. It is based upon the average anomalies of sea surface temperatures (SST) in the North Atlantic basin, typically over 0-80N.\n",
    "(source: https://climatedataguide.ucar.edu/climate-data/atlantic-multi-decadal-oscillation-amo)\n",
    "<br /><br />\n",
    "\n",
    "Siberian Snow Cover - http://climate.rutgers.edu/snowcover/files/moncov.eurasia.txt # sq. km <br />\n",
    "(source: https://www.nohrsc.noaa.gov/nh_snowcover/)\n",
    "<br /><br />\n",
    "\n",
    "UK temperature - https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/Rainfall/date/England.txt <br />\n",
    "<br />\n",
    "\n",
    "UK rainfall - https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/Tmean/date/England.txt <br />\n",
    "<br />\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b1395",
   "metadata": {},
   "source": [
    "First, let's gather all of the data listed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b21799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from scipy import stats\n",
    "%matplotlib qt\n",
    "\n",
    "def month_cols_to_rows(df, output_value_col_name):\n",
    "    \"\"\"\n",
    "    Formats a string containing time series data to a pandas DataFrame\n",
    "\n",
    "    This function simply wraps the ``+`` operator, and does not\n",
    "    do anything interesting, except for illustrating what\n",
    "    the docstring of a very simple function looks like.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num1 : int\n",
    "        First number to add.\n",
    "    num2 : int\n",
    "        Second number to add.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The sum of ``num1`` and ``num2``.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(df.columns) != 12:\n",
    "        print('Are you sure there are 12 months (plus the year as index) present in this DataFrame?')\n",
    "        return\n",
    "    new_df = []\n",
    "    for y in df.index:\n",
    "        month_start = 0\n",
    "        for row in df[df.index == y].values:\n",
    "            for r in row:\n",
    "                month_start = month_start++1\n",
    "                new_df.append([y,month_start,r])\n",
    "\n",
    "    new_df=pd.DataFrame(new_df)\n",
    "    new_df.columns = ['Year', 'Month', output_value_col_name]\n",
    "    #new_df = new_df.set_index('Year')\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def format_type_1(s):\n",
    "    \"\"\"\n",
    "    Formats a string containing time series data to a pandas DataFrame\n",
    "\n",
    "    This function simply wraps the ``+`` operator, and does not\n",
    "    do anything interesting, except for illustrating what\n",
    "    the docstring of a very simple function looks like.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num1 : int\n",
    "        First number to add.\n",
    "    num2 : int\n",
    "        Second number to add.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The sum of ``num1`` and ``num2``.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = StringIO(re.sub(' +', ',', s))\n",
    "\n",
    "    d = pd.read_csv(s)\n",
    "\n",
    "    # When reading a string as a CSV, pandas automatically assigns the first row as the header, \n",
    "    # we want to move that header back to the rows and recreate an appropriate header\n",
    "    d.loc[len(d)] = list(d.columns)\n",
    "    d.columns = np.arange(0,len(d.columns),1)\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939c1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "r = requests.get('http://climate.rutgers.edu/snowcover/files/moncov.eurasia.txt')\n",
    "eurasian_snow_cover_data = format_type_1(r.text)\n",
    "eurasian_snow_cover_data.columns = ['Year', 'Month', 'Eurasian_Snow_Cover']\n",
    "eurasian_snow_cover_data = eurasian_snow_cover_data.apply(pd.to_numeric, errors='coerce')\n",
    "eurasian_snow_cover_data['Eurasian_Snow_Cover'] = eurasian_snow_cover_data['Eurasian_Snow_Cover']/10e6 # Sq Km to Mil Sq km\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472963f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# r = requests.get(\"https://www.metoffice.gov.uk/hadobs/hadcet/data/meantemp_daily_totals.txt\")\n",
    "# s = StringIO(re.sub(' +', ',', r.text)) #replace all spaces (and consecutive spaces) with commas\n",
    "# CET = pd.read_csv(s)\n",
    "# CET = CET.set_index('Date')\n",
    "# CET['Year and Month'] = CET.index.str[:-3]\n",
    "# CE_Monthly = CET.groupby('Year and Month').mean()\n",
    "# CE_Monthly = CE_Monthly.reset_index()\n",
    "\n",
    "# CE_Monthly[['Year', 'Month']] = CE_Monthly['Year and Month'].str.split('-', expand=True)\n",
    "# CE_Monthly = CE_Monthly.drop(columns = 'Year and Month')\n",
    "# CE_Monthly = CE_Monthly.rename(columns={'Value':'CET Mean'})\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848624fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "r = requests.get(\"https://origin.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/detrend.nino34.ascii.txt\")\n",
    "s = StringIO(re.sub(' +', ',', r.text[1:])) #replace all spaces (and consecutive spaces) with commas\n",
    "Nino = pd.read_csv(s)\n",
    "Nino = Nino[['YR','MON','TOTAL']]\n",
    "Nino = Nino.rename(columns = {'YR':'Year','MON':'Month','TOTAL':'Nino3.4'})\n",
    "Nino = Nino.apply(pd.to_numeric, errors='coerce')\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90325b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "r = requests.get(\"https://www.ncei.noaa.gov/pub/data/cmb/ersst/v5/index/ersst.v5.pdo.dat\")\n",
    "s = StringIO(re.sub(' +', ',', r.text[18:])) #replace all spaces (and consecutive spaces) with commas\n",
    "PDO = pd.read_csv(s)\n",
    "PDO = PDO.set_index('Year')\n",
    "PDO = month_cols_to_rows(PDO, 'PDO')\n",
    "PDO = PDO.apply(pd.to_numeric, errors='coerce')\n",
    "############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e24b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "r = requests.get(\"https://www.cpc.ncep.noaa.gov/data/indices/soi\")\n",
    "s = StringIO(re.sub(' +', ',', r.text[242:-6485].replace('-999.9',' '))) #replace all spaces (and consecutive spaces) with commas\n",
    "\n",
    "SOI = pd.read_csv(s)\n",
    "SOI = SOI.set_index('YEAR')\n",
    "SOI = SOI.drop(columns = ['Unnamed: 13'])\n",
    "SOI = month_cols_to_rows(SOI, 'SOI')\n",
    "SOI = SOI.apply(pd.to_numeric, errors='coerce')\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec337c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "sunspots = pd.read_json(\"https://services.swpc.noaa.gov/json/solar-cycle/observed-solar-cycle-indices.json\")\n",
    "sunspots = sunspots[['time-tag','ssn']]\n",
    "sunspots[['Year', 'Month']]=sunspots['time-tag'].str.split('-', expand=True)\n",
    "sunspots = sunspots.drop(columns = ['time-tag'])\n",
    "sunspots = sunspots.rename(columns={'ssn': 'Sunspots'})\n",
    "sunspots = sunspots.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9599cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.cpc.ncep.noaa.gov/data/indices/qbo.u50.index\")\n",
    "s = StringIO(re.sub(' +', ',', r.text[243:4765].replace('-999.9',' ')))\n",
    "QBO = pd.read_csv(s)\n",
    "QBO = QBO.drop(columns = ['Unnamed: 13'])\n",
    "QBO = QBO.set_index('YEAR')\n",
    "QBO = month_cols_to_rows(QBO, 'QBO')\n",
    "QBO = QBO.apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99062d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "r = requests.get(\"https://psl.noaa.gov/data/correlation/amon.us.data\")\n",
    "AMO = format_type_1(r.text[21:-135])\n",
    "AMO = AMO.set_index(0)\n",
    "AMO = month_cols_to_rows(AMO, 'AMO')\n",
    "AMO = AMO.apply(pd.to_numeric, errors='coerce')\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d6d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "r = requests.get(\"https://www.cpc.ncep.noaa.gov/products/precip/CWlink/daily_ao_index/monthly.ao.index.b50.current.ascii\")\n",
    "AO = format_type_1(r.text[2:])\n",
    "AO.columns = ['Year', 'Month', 'AO']\n",
    "AO = AO.apply(pd.to_numeric, errors='coerce')\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1552b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "r = requests.get(\"https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii\")\n",
    "NAO = format_type_1(r.text[2:])\n",
    "NAO.columns = ['Year', 'Month', 'NAO']\n",
    "NAO = NAO.apply(pd.to_numeric, errors='coerce')\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0087334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "r = requests.get(\"https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.pna.monthly.b5001.current.ascii\")\n",
    "PNA = format_type_1(r.text[2:])\n",
    "PNA.columns = ['Year', 'Month', 'PNA']\n",
    "PNA = PNA.apply(pd.to_numeric, errors='coerce')\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bd6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "r = requests.get(\"https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/Rainfall/date/England.txt\")\n",
    "s = StringIO(re.sub(' +', ',', r.text[264:]))\n",
    "UK_rainfall = pd.read_csv(s)\n",
    "UK_rainfall = UK_rainfall.drop(columns = ['win','spr','sum','aut','ann'])\n",
    "UK_rainfall = UK_rainfall.set_index('year')\n",
    "UK_rainfall = month_cols_to_rows(UK_rainfall, 'UK_rainfall')\n",
    "UK_rainfall = UK_rainfall.apply(pd.to_numeric, errors='coerce')\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "648bacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "r = requests.get(\"https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/Tmean/date/England.txt\")\n",
    "s = StringIO(re.sub(' +', ',', r.text[259:]))\n",
    "UK_mean_temp = pd.read_csv(s)\n",
    "UK_mean_temp = UK_mean_temp.drop(columns = ['win','spr','sum','aut','ann'])\n",
    "UK_mean_temp = UK_mean_temp.set_index('year')\n",
    "UK_mean_temp = month_cols_to_rows(UK_mean_temp, 'UK_mean_temp')\n",
    "UK_mean_temp = UK_mean_temp.apply(pd.to_numeric, errors='coerce')\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b738f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.merge(eurasian_snow_cover_data,SOI, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,Nino, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,PDO, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,sunspots, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,QBO, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,AMO, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,AO, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,NAO, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,PNA, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,UK_rainfall, on=['Year', 'Month'])\n",
    "features_df = pd.merge(features_df,UK_mean_temp, on=['Year', 'Month'])\n",
    "\n",
    "\n",
    "\n",
    "features_df = features_df.sort_values(by=['Year', 'Month'])\n",
    "features_df['Year and Month'] = pd.to_datetime(features_df['Year'].astype(str)+\"-\"+features_df['Month'].astype(str), format = '%Y-%m')\n",
    "features_df = features_df.set_index('Year and Month')\n",
    "features_df = features_df.drop(columns = ['Year', 'Month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0926a13",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Great, now the data needs a bit of cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df2e587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year and Month\n",
      "1979-01-01    0\n",
      "1979-02-01    0\n",
      "1979-03-01    0\n",
      "1979-04-01    0\n",
      "1979-05-01    0\n",
      "             ..\n",
      "2022-05-01    0\n",
      "2022-06-01    0\n",
      "2022-07-01    0\n",
      "2022-08-01    0\n",
      "2022-09-01    0\n",
      "Length: 525, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features_df = features_df.replace(99.99, np.nan)\n",
    "features_df = features_df.replace(-99.99, np.nan)\n",
    "print(features_df.isna().sum(axis=1))\n",
    "features_df = features_df.interpolate() # interpolate between points around missing values, if there's a Nan at the last row, just use the previous months value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f32e36",
   "metadata": {},
   "source": [
    "Now, we need to get the mean temperature for a given winter. Because the winter months overlap with multiple years (i.e. December, January and Feburary), we need to account for this. For ease of usability, we will simply take the first year of the winter period as it's identifying year. This saves us having to use a string such as '2020/2021', which is a bit more cumbersome to filter by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1d56db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "c:\\users\\johnd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "def combine_winters(features_df, winter_months):\n",
    "    winter_month_mask = [x in winter_months for x in features_df.index.month]\n",
    "    all_winters = features_df.loc[winter_month_mask,:]\n",
    "    \n",
    "    \n",
    "    all_winters.loc[:,'Winter Start Year'] = 0\n",
    "    for ind in all_winters.index:\n",
    "        if ind.month > 11:\n",
    "            all_winters.loc[ind, 'Winter Start Year'] = ind.year\n",
    "        elif ind.month < 3:\n",
    "            all_winters.loc[ind, 'Winter Start Year'] = ind.year-1\n",
    "            \n",
    "    all_winter_means = all_winters.groupby('Winter Start Year').mean()['UK_mean_temp']#.values\n",
    "    all_winter_means.name = 'Winter Mean'\n",
    "    \n",
    "    return all_winters, all_winter_means\n",
    "\n",
    "\n",
    "winter_months = [12,1,2]\n",
    "\n",
    "all_winters, all_winter_means = combine_winters(features_df, winter_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545c26b",
   "metadata": {},
   "source": [
    "Some EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4aad131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Winter Start Year'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_winter_means.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa7071",
   "metadata": {},
   "source": [
    "Unsurprisingly, the data shows that UK Winters are getting warmer (likely as a result of climate change). Let's have a play witht data to see what it shows. Below, I'll look at the data for November and see how well it is correlated to the winter mean temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b94e1e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='Eurasian_Snow_Cover'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='Eurasian_Snow_Cover'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='SOI'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='SOI'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='Nino3.4'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='Nino3.4'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='PDO'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='PDO'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='Sunspots'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='Sunspots'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='QBO'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='QBO'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='AMO'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='AMO'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='AO'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='AO'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='NAO'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='NAO'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='PNA'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='PNA'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='UK_rainfall'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='UK_rainfall'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='UK_mean_temp'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='UK_mean_temp'>],\n",
       "       [<AxesSubplot:xlabel='Eurasian_Snow_Cover', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='SOI', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='Nino3.4', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='PDO', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='Sunspots', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='QBO', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='AMO', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='AO', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='NAO', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='PNA', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='UK_rainfall', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='UK_mean_temp', ylabel='Winter Mean'>,\n",
       "        <AxesSubplot:xlabel='Winter Mean', ylabel='Winter Mean'>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_months_with_winter_means = pd.merge(features_df,all_winter_means, left_on=features_df.index.year, right_index=True)\n",
    "all_months_with_winter_means = all_months_with_winter_means.drop(columns=['key_0'])\n",
    "\n",
    "corr_mat = all_months_with_winter_means[all_months_with_winter_means.index.month==11].corr()\n",
    "sn.heatmap(corr_mat, annot=True)\n",
    "plt.show()\n",
    "\n",
    "pd.plotting.scatter_matrix(all_months_with_winter_means[all_months_with_winter_means.index.month==11], diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "id": "4e044710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = all_months_with_winter_means['AMO'].plot(legend=True)\n",
    "all_months_with_winter_means['Winter Mean'].plot(ax=ax, secondary_y=True, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ae9a3",
   "metadata": {},
   "source": [
    "Looks like the AMO is the best correlated feature with Winter Mean. The AMO is a measure of log term sea surface temperature in the North Atlantic ocean. A positive correlation indicates that when the AMO cooler in November, this implies the UK may experience a colder winter overall. However, this could be a case of correlation not equaling causation, as the sea surface temperature has been increasing due to climate changes, while UK winters have been getting warmer.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad33151",
   "metadata": {},
   "source": [
    "## Method 1: Finding Analogues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7686f4",
   "metadata": {},
   "source": [
    "Now that we have all of the data, we can begin our analysis. \n",
    "Firstly, let's try to find analogues to the data we are interested in, i.e. have there been any similar weather patterns seen in the past, and if so, did those years produce cold winters?\n",
    "\n",
    "We do this by selecting a month that we are interested in, such as September 2022, and calculate the Euclidian Distance of that month to all previous Septembers:\n",
    "\n",
    "$$ s = \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)} $$, where n is the number of features </b></b>\n",
    "\n",
    "If we chose multiple months, we can take the average of the ED for each month we choose. <br /> <br />\n",
    "For example, let's say we wanted to find the most similar Septembers and Octobers to September/October 2022. \n",
    "The function 'find_analogue_years' will return the top n most similar year, and the 'get_temperatures_of_similar_years' will find the mean winter temperature of those years, which we can then compare to the actual mean winter temperature of the selected year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1715,
   "id": "6a9548fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "\n",
    "def euclidian(arr_a, arr_b):\n",
    "    return np.sum((arr_a-arr_b)**2)**0.5\n",
    "\n",
    "\n",
    "def find_analogue_years(search_months, search_year, n_analogues):\n",
    "    month_mask = [x in search_months for x in features_df.index.month]\n",
    "    months_to_search_for = features_df[month_mask & (features_df.index.year==search_year)]\n",
    "\n",
    "    ############# \n",
    "\n",
    "    months_to_search = features_df[month_mask]\n",
    "    \n",
    "    \n",
    "    \n",
    "    years = pd.DataFrame([], columns = ['Similarity'])\n",
    "    for ind, data in months_to_search.iterrows():\n",
    "        if ind.year == search_year:\n",
    "            continue\n",
    "        \n",
    "        ed = euclidian(data.values, months_to_search_for.values)\n",
    "        \n",
    "        if ind.year in years.index:\n",
    "            #years.loc[ind.year]=np.mean([years.loc[ind.year].values[0], abs(row[['Nino3.4', 'AMO', 'AO', 'NAO']].values -months_to_search_for[['Nino3.4', 'AMO', 'AO', 'NAO']].values).sum()])\n",
    "            years.loc[ind.year]=np.nanmean([years.loc[ind.year].values[0], ed])\n",
    "            \n",
    "        else:\n",
    "            #years.loc[ind.year]=abs(row[['Nino3.4', 'AMO', 'AO', 'NAO']].values -months_to_search_for[['Nino3.4', 'AMO', 'AO', 'NAO']].values).sum()\n",
    "            years.loc[ind.year]=ed\n",
    "            \n",
    "            \n",
    "    most_similar_years = years.nsmallest(n_analogues, 'Similarity')\n",
    "    return most_similar_years\n",
    "\n",
    "\n",
    "def get_temperatures_of_similar_years(all_winters, most_similar_years):\n",
    "    temps = []\n",
    "    for y in most_similar_years.index:\n",
    "        temps.append(all_winters.loc[(all_winters['Winter Start Year'] ==y)]['UK_mean_temp'].mean())\n",
    "    temps = np.array(temps)\n",
    "    return temps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "id": "9b1b9ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: this winter (as compared with the data from 2022) \n",
      "will be in the 63.64th percentile of all UK winters in the dataset\n"
     ]
    }
   ],
   "source": [
    "## Finding Analogues\n",
    "\n",
    "months = [9]\n",
    "\n",
    "current_year = 2022\n",
    "\n",
    "\n",
    "most_similar_years = find_analogue_years(months, current_year, 3)\n",
    "\n",
    "temps = get_temperatures_of_similar_years(all_winters, most_similar_years)\n",
    "\n",
    "plt.hist(all_winter_means)\n",
    "plt.axvline(np.mean(all_winter_means), c='red')\n",
    "plt.axvline(np.mean(all_winter_means)+np.std(all_winter_means), c='yellow')\n",
    "plt.axvline(np.mean(all_winter_means)-np.std(all_winter_means), c='yellow')\n",
    "plt.hist(temps)    \n",
    "\n",
    "\n",
    "percentile = stats.percentileofscore(all_winter_means.values, np.mean(temps))\n",
    "print(\"Prediction: this winter (as compared with the data from {date}) \\nwill be in the {p}th percentile of all UK winters in the dataset\".format(date = current_year, p = round(100-percentile,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3ad49",
   "metadata": {},
   "source": [
    "As we can see from the histogram generated, most UK winters tend to be between 3°C - 5.5°C. We can also see that for 2022, the average of the most similar years is ~4°C, well within the bounds of a 'normal' UK winter. \n",
    "\n",
    "But does this mean anything? Is this prediction method any good?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f851017",
   "metadata": {},
   "source": [
    "We now need to test how reliable this method is.So let's see how well the predicted temperatures match the actual temperatures over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "501e0274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################\n",
      "Months: [9]\n",
      "Correlation: 0.2793496919412732\n",
      "Covariance: \n",
      "[[1.29841024 0.28562262]\n",
      " [0.28562262 0.80515012]]\n",
      "r^2:-0.18055949102460334\n",
      "################\n",
      "Months: [10]\n",
      "Correlation: 0.015190011242696783\n",
      "Covariance: \n",
      "[[1.29841024 0.01461886]\n",
      " [0.01461886 0.7133441 ]]\n",
      "r^2:-0.5402535305500853\n",
      "################\n",
      "Months: [11]\n",
      "Correlation: 0.18494080817878106\n",
      "Covariance: \n",
      "[[1.29841024 0.17115971]\n",
      " [0.17115971 0.65966839]]\n",
      "r^2:-0.26662322382673564\n",
      "################\n",
      "Months: [9, 10, 11]\n",
      "Correlation: -0.41827794958057524\n",
      "Covariance: \n",
      "[[ 1.29841024 -0.39901224]\n",
      " [-0.39901224  0.70085887]]\n",
      "r^2:-1.1686624233096858\n",
      "################\n",
      "Months: [9, 10]\n",
      "Correlation: -0.11216236454338616\n",
      "Covariance: \n",
      "[[ 1.29841024 -0.11104651]\n",
      " [-0.11104651  0.75492463]]\n",
      "r^2:-0.7591822258528571\n",
      "################\n",
      "Months: [10, 11]\n",
      "Correlation: -0.13004611296040422\n",
      "Covariance: \n",
      "[[ 1.29841024 -0.11165282]\n",
      " [-0.11165282  0.5677181 ]]\n",
      "r^2:-0.6455817660426573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################################################################\n",
    "def evaluate_method1(all_winters, months_to_check,axs, subplotx, subploty):\n",
    "    print(\"################\")\n",
    "    print(\"Months: \"+str(months_to_check))\n",
    "    predicted_based_on_analogues = []\n",
    "    actual_winter_temps = []\n",
    "    for i in np.arange(min(all_winters.index.year),max(all_winters.index.year),1):\n",
    "\n",
    "        similar_years = find_analogue_years(months_to_check, i, 2)\n",
    "        temps = get_temperatures_of_similar_years(all_winters, similar_years)\n",
    "\n",
    "        predicted_based_on_analogues.append(np.nanmean(temps))\n",
    "        actual_winter_temps.append(all_winter_means[all_winter_means.index==i].values[0])\n",
    "\n",
    "    axs[subplotx,subploty].set_title(\"Months: \"+','.join(str(i) for i in months_to_check))\n",
    "    axs[subplotx,subploty].set_xlabel('Actual Winter Mean Temperatures')\n",
    "    axs[subplotx,subploty].set_ylabel('Predicted Winter Mean\\n Temperatures \\n(based on analogue years)')\n",
    "    axs[subplotx,subploty].plot(np.array(actual_winter_temps), np.array(actual_winter_temps), c='red')\n",
    "    axs[subplotx,subploty].scatter(np.array(actual_winter_temps), np.array(predicted_based_on_analogues))\n",
    "\n",
    "    corr, _ = pearsonr(np.array(actual_winter_temps), np.array(predicted_based_on_analogues))\n",
    "    print(\"Correlation: \"+ str(corr))\n",
    "    print('Covariance: \\n'+ str(np.cov(np.array(actual_winter_temps), np.array(predicted_based_on_analogues))))\n",
    "    print('r^2:'+ str(r2_score(np.array(actual_winter_temps), np.array(predicted_based_on_analogues))))\n",
    "\n",
    "    return\n",
    "\n",
    "fig, axs = plt.subplots(3,2)\n",
    "fig.tight_layout(pad=3.0)\n",
    "months_to_check = [9,]\n",
    "evaluate_method1(all_winters, months_to_check,axs, 0,0)\n",
    "months_to_check = [10,]\n",
    "evaluate_method1(all_winters, months_to_check,axs, 1,0)\n",
    "months_to_check = [11,]\n",
    "evaluate_method1(all_winters, months_to_check,axs, 2,0)\n",
    "months_to_check = [9,10,11]\n",
    "evaluate_method1(all_winters, months_to_check,axs, 0,1)\n",
    "months_to_check = [9,10]\n",
    "evaluate_method1(all_winters, months_to_check,axs, 1,1)\n",
    "months_to_check = [10,11]\n",
    "evaluate_method1(all_winters, months_to_check,axs, 2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c7f65",
   "metadata": {},
   "source": [
    "As you would expect, using the data from November produces a better correlation with the Winter Mean Temperature than the October data (although not the case for September (!)). Interestingly, adding more months does not seem to improve the prediction. This could be due to the changable nature of the weather, meaning that it's difficult to find 3 consecutive months that are similar to 3 other consecutive months!\n",
    "\n",
    "Overall, it doesn't seem that this is a very good way to predict this years Winter Mean temperature, as it seems to be predicting the something very close to the mean Winter Temperature. This is true no matter how many similar years you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11334cb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208eb568",
   "metadata": {},
   "source": [
    "# Method 2: Machine learning\n",
    "\n",
    "Let's see if we can use ML to perform a better prediction. First, we need to split the data up into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20694d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ML training with single month\n",
    "\n",
    "def dataframe_to_training_and_test_sets(df, pct_split, months_used_for_prediction, label_col):\n",
    "    \n",
    "    autumn = [x in months_used_for_prediction for x in df.index.month]\n",
    "    df_filtered = df[autumn]\n",
    "    \n",
    "    df_train = df_filtered.loc[df_filtered.index[:int(len(df_filtered.index)*pct_split)],:]\n",
    "    df_test = df_filtered.loc[df_filtered.index[int(len(df_filtered.index)*pct_split):],:]\n",
    "    \n",
    "\n",
    "    y_train = df_train[label_col].round(3).values\n",
    "    X_train = df_train.drop(columns = [label_col]).values\n",
    "\n",
    "    y_test = df_test[label_col].round(3).values\n",
    "    X_test = df_test.drop(columns = [label_col]).values\n",
    "    return X_train,y_train, X_test, y_test, df_train, df_test\n",
    "\n",
    "label_col = 'Winter Mean'\n",
    "all_months_with_winter_means['Month'] = all_months_with_winter_means.index.month\n",
    "all_months_with_winter_means_shuffled = all_months_with_winter_means.sample(frac=1, random_state=123) # going to shuffle the data so that we have some of the more recent, warmer years in the training set\n",
    "X_train, y_train, X_test, y_test, df_train, df_test = dataframe_to_training_and_test_sets(all_months_with_winter_means_shuffled, 0.8, [9,10,11], label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831c526",
   "metadata": {},
   "source": [
    "Then we need to find a suitable regression model to perform our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "07d5d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "R^2:  0.1603952612925963\n",
      "SVR\n",
      "R^2:  -0.007026424218675276\n",
      "RFR\n",
      "R^2:  0.45951719639670074\n",
      "GPR\n",
      "R^2:  -13.434594147715726\n",
      "GBR\n",
      "R^2:  0.4311576875086034\n",
      "XGR\n",
      "R^2:  0.319008600725606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    models = [\n",
    "              ('LR', LinearRegression()), \n",
    "              ('SVR', SVR()),\n",
    "              ('RFR', RandomForestRegressor()),\n",
    "              ('GPR', GaussianProcessRegressor()), \n",
    "              ('GBR', GradientBoostingRegressor()),\n",
    "                ('XGR', XGBRegressor()),\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['r2']\n",
    "    for name, model in models:\n",
    "            kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "            cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "            clf = model.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(name)\n",
    "            print(\"R^2: \",r2_score(y_test, y_pred))\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "    return \n",
    "\n",
    "run_exps(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f4702",
   "metadata": {},
   "source": [
    "It looks like Linear Regression is the model with the best r^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c401b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_type, X_train, y_train, X_test, y_test):\n",
    "    model = model_type\n",
    "    model.fit(X_train,y_train)\n",
    "    # define model evaluation method\n",
    "    \n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    scores = cross_val_score(model, X_train,y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    scores = np.abs(scores)\n",
    "    print('Mean MAE: %.5f (%.8f)' % (scores.mean(), scores.std()) )\n",
    "\n",
    "    mea = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    mape = mean_absolute_percentage_error(y_test, model.predict(X_test))\n",
    "    \n",
    "    # binomial confidence interval\n",
    "    from math import sqrt\n",
    "    interval = 1.96 * scores.std()\n",
    "    print('CI at 95%: +/-', round(interval,3))    \n",
    "    \n",
    "\n",
    "    r2 = r2_score(y_test, model.predict(X_test))\n",
    "    print(\"r^2 (test set): \", r2)\n",
    "\n",
    "    \n",
    "    print(\"MAE (test set): \",mea)\n",
    "    return model, interval\n",
    "\n",
    "def scatter_plot_of_results(y_test, predicted_vals, interval):\n",
    "    plt.scatter(y_test, predicted_vals, label='Predictions')\n",
    "    plt.errorbar(y_test, predicted_vals, yerr=interval, fmt='o')\n",
    "    plt.plot(y_test, y_test, label='Perfect prediction line', c='r')\n",
    "    plt.xlabel('Actual ($^\\circ$C)')\n",
    "    plt.ylabel('Predicted ($^\\circ$C)')\n",
    "    plt.title('Actual vs predicted')\n",
    "    plt.legend()\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f9466833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.78921 (0.20626558)\n",
      "CI at 95%: +/- 0.404\n",
      "r^2 (test set):  0.4176885912986841\n",
      "MAE (test set):  0.8003565384615388\n"
     ]
    }
   ],
   "source": [
    "model, interval = train_and_evaluate(RandomForestRegressor(), X_train, y_train, X_test, y_test)\n",
    "scatter_plot_of_results(y_test, model.predict(X_test), interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5488dd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.800080000000001"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_forecast(percentile):\n",
    "    forecasts = {0: 'Very Cold', 20: 'Colder than average', 40: 'Around Average', 60: 'Milder than average', 80: 'Very Mild',100: \"\"}\n",
    "    keys = list(forecasts.keys())\n",
    "    predicted_forecast = forecasts[[keys[k] for k in range(len(keys)) if percentile > keys[k] and  percentile < keys[k+1]][0]]\n",
    "    return predicted_forecast\n",
    "\n",
    "def winter_prediction(percentile, date):\n",
    "    print(\"Prediction: this winter (as predicted with the latest data from {date} \\nwill be in the {p}th percentile of all UK winters from the dataset\\n\".format(date = predict_month, p = round(percentile,2)))\n",
    "\n",
    "features_df['Month'] = features_df.index.month\n",
    "predicted_from_date = features_df.index[-1]\n",
    "predict_this_winter = model.predict(np.array(features_df.loc[predicted_from_date].values).reshape(1,-1))[0]\n",
    "predict_this_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "330b7917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: this winter (as predicted with the latest data from 2022-08-01 00:00:00 \n",
      "will be in the 56.82th percentile of all UK winters from the dataset\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Around Average'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile = stats.percentileofscore(all_winter_means.values, predict_this_winter)\n",
    "winter_prediction(percentile, predicted_from_date)\n",
    "get_forecast(percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5d8f7",
   "metadata": {},
   "source": [
    "Overall, this method does much better than the analogue method we used before, although it could be improved. Can we do better than this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a92fbf",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56f600",
   "metadata": {},
   "source": [
    "# Method 3: ML with a lookback\n",
    "\n",
    "This method is similar to method 2, however, we are going to add a lookback to the features, i.e. not only taking into account the current months data as a feature, but also previous months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bb3e3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ML training with many months\n",
    "\n",
    "def dataframe_with_lookback(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [(df.columns[j]+'(t-%d)' % (i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [(df.columns[j]) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [(df.columns[j]+'(t+%d)' % (i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9c822",
   "metadata": {},
   "source": [
    "To give the model the best chance of making a good prediction, let's use the data for November (as the latest data), and lookback 2 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "56a250eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted = dataframe_with_lookback(all_months_with_winter_means, n_in=2, n_out=1, dropnan=True)\n",
    "df_shifted['Month'] = df_shifted.index.month\n",
    "\n",
    "df_shifted = df_shifted.drop(columns = [col for col in df_shifted.columns if label_col in col and col != label_col])\n",
    "\n",
    "df_shifted = df_shifted.sample(frac=1.0, random_state=123)\n",
    "X_train, y_train, X_test, y_test, df_train, df_test = dataframe_to_training_and_test_sets(df_shifted, 0.8, [9,10,11], label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8dcb9ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "R^2:  -0.10098019977034256\n",
      "SVR\n",
      "R^2:  -0.21862449182580934\n",
      "RFR\n",
      "R^2:  0.17055918701545636\n",
      "GPR\n",
      "R^2:  -14.738106375097647\n",
      "GBR\n",
      "R^2:  0.3557768142189047\n",
      "XGR\n",
      "R^2:  0.1584880354841618\n"
     ]
    }
   ],
   "source": [
    "run_exps(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469da8c8",
   "metadata": {},
   "source": [
    "XGBRegressor seems to be the best performer, albeit pretty poor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0bca6754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.90292 (0.13446777)\n",
      "CI at 95%: +/- 0.264\n",
      "r^2 (test set):  0.1584880354841618\n",
      "MAE (test set):  0.8392910396869365\n"
     ]
    }
   ],
   "source": [
    "model, interval = train_and_evaluate(XGBRegressor(), X_train, y_train, X_test, y_test)\n",
    "scatter_plot_of_results(y_test, model.predict(X_test), interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "42eac152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: this winter (as predicted with the latest data from 2022-08-01 00:00:00 \n",
      "will be in the 36.36th percentile of all UK winters from the dataset\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Colder than average'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_from_date = df_shifted.index[-1]\n",
    "features = df_shifted.drop(columns=['Winter Mean']).loc[predicted_from_date]\n",
    "\n",
    "predict_this_winter = model.predict(features.values.reshape(1,-1))[0]\n",
    "\n",
    "percentile = stats.percentileofscore(all_winter_means.values, predict_this_winter)\n",
    "winter_prediction(percentile, predicted_from_date)\n",
    "get_forecast(percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720feca",
   "metadata": {},
   "source": [
    "Hmm, the model does not seemed to have improved with more features. Perhaps there are some redundant features, let's rank the features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4a606f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK_rainfall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nino3.4(t-1)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunspots(t-1)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOI(t-1)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Name Ranking\n",
       "0    UK_rainfall       1\n",
       "1   Nino3.4(t-1)       1\n",
       "2  Sunspots(t-1)       1\n",
       "3       SOI(t-1)       1\n",
       "4            AMO       1\n",
       "5          Month       2"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Feature Importance Section\n",
    "\n",
    "# define the method\n",
    "rfe = RFE(estimator=XGBRegressor(), n_features_to_select=5)\n",
    "rfe.fit(X_train,y_train)\n",
    "\n",
    "df_feature_selection = pd.DataFrame([], columns = ['Feature Name', 'Ranking'])\n",
    "for i in range(X_train.shape[1]):\n",
    "    #print('Column: %d, Name: %s,  Selected %s, Rank: %.3f' % (i,df_train.drop(columns=['Winter Mean']).columns[i],  rfe.support_[i], rfe.ranking_[i]))\n",
    "    df_feature_selection = df_feature_selection.append({'Feature Name': df_train.drop(columns=['Winter Mean']).columns[i], 'Ranking': rfe.ranking_[i]}, ignore_index=True)\n",
    "\n",
    "df_feature_selection.sort_values('Ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f19878de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shifted = df_shifted[['UK_rainfall','NAO', 'QBO', 'AO(t-1)', 'AMO','Month', 'Winter Mean']]\n",
    "df_shifted = df_shifted[['UK_rainfall','Nino3.4(t-1)', 'Sunspots(t-1)', 'SOI(t-1)', 'AMO','Month', 'Winter Mean']]\n",
    "X_train, y_train, X_test, y_test, df_train, df_test = dataframe_to_training_and_test_sets(df_shifted, 0.8, [9,10,11], 'Winter Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1a36c061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.70440 (0.17346970)\n",
      "CI at 95%: +/- 0.34\n",
      "r^2 (test set):  -0.2171636331814586\n",
      "MAE (test set):  1.1042655073312613\n"
     ]
    }
   ],
   "source": [
    "model, interval = train_and_evaluate(XGBRegressor(), X_train, y_train, X_test, y_test)\n",
    "scatter_plot_of_results(y_test, model.predict(X_test), interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75269e00",
   "metadata": {},
   "source": [
    "It doesn't seem like filtering the features produces any gains. Lesson learned, more features does not alway equal a better model.\n",
    "Intuitively this makes sense, what matters most when trying to predict weather/climate is the most recent observations, not something that occurs 2 months ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3014c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7256aa",
   "metadata": {},
   "source": [
    "# Method 4: Using ML to predict next months mean temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "45bd23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted = dataframe_with_lookback(all_months_with_winter_means.drop(columns='Winter Mean'), n_in=2, n_out=1, dropnan=True)\n",
    "df_shifted['Month'] = df_shifted.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1af9d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted['UK_mean_temp (t+1)'] = df_shifted['UK_mean_temp']\n",
    "df_shifted['UK_mean_temp (t+1)'] = df_shifted.shift(-1)['UK_mean_temp (t+1)']\n",
    "df_shifted = df_shifted.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "354d2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, df_train, df_test = dataframe_to_training_and_test_sets(df_shifted, 0.8, [8,9,10,11], 'UK_mean_temp (t+1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b80855b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "R^2:  0.8309971597756792\n",
      "SVR\n",
      "R^2:  0.048349060489405904\n",
      "RFR\n",
      "R^2:  0.8577418919262662\n",
      "GPR\n",
      "R^2:  -7.868236559322128\n",
      "GBR\n",
      "R^2:  0.8465402423380176\n",
      "XGR\n",
      "R^2:  0.8345946220199745\n"
     ]
    }
   ],
   "source": [
    "run_exps(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dd2ebd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 1.13651 (0.18490903)\n",
      "CI at 95%: +/- 0.362\n",
      "r^2 (test set):  0.8345946220199745\n",
      "MAE (test set):  1.1172714396885464\n"
     ]
    }
   ],
   "source": [
    "model, interval = train_and_evaluate(XGBRegressor(), X_train, y_train, X_test, y_test)\n",
    "scatter_plot_of_results(y_test, model.predict(X_test), interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4cb553e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted2 = dataframe_with_lookback(features_df, n_in=2, n_out=1, dropnan=True)\n",
    "df_shifted2['Month'] = df_shifted2.index.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "59bcaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_month = df_shifted2.index[-1] # get last row of dataset (should be the latest data)\n",
    "predict_next_month = model.predict(df_shifted2[df_shifted2.index == predict_month].values.reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b5ec3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.88185 +/- 0.3624216999658043\n",
      "Predicted forecast for month of 2022-10 \n",
      "Colder than average\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "print(predict_next_month, \"+/-\", interval)\n",
    "percentile = stats.percentileofscore(features_df[features_df.index.month ==predict_month.month+1]['UK_mean_temp'], predict_next_month)\n",
    "\n",
    "\n",
    "print(\"Predicted forecast for month of {date} \\n{fc}\".format(date = str((predict_month+timedelta(days=31)).date())[:-3], fc= get_forecast(percentile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5fc2d5",
   "metadata": {},
   "source": [
    "***\n",
    "Unsurprisingly, predicting the weather is difficult! Although, we can still draw some conclusions from this analysis.\n",
    "1. Using climate index analogues is not a good way of predicting\n",
    "2. Adding data from n months ago does not improve model performance\n",
    "3. It's much easier to predict next months mean temperature than the average of the next 3 months\n",
    "4. It's very difficult to say with any confidence what the UK winter of 2022/2023 is going to be like, we'll have to wait and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c547e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
